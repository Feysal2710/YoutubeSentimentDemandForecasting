{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053d2297-16e2-45ed-888d-7ec1e39f806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.8208955223880597, 1: 0.9683098591549296, 2: 1.3349514563106797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading FastText: 2000001it [00:41, 48331.47it/s]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m3,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> (11.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,000,000\u001b[0m (11.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> (11.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,000,000\u001b[0m (11.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.3478 - loss: 1.1009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.3460 - loss: 1.1008 - val_accuracy: 0.3816 - val_loss: 1.0881\n",
      "Epoch 2/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.4647 - loss: 1.0704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - accuracy: 0.4652 - loss: 1.0697 - val_accuracy: 0.4541 - val_loss: 1.0554\n",
      "Epoch 3/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.5473 - loss: 0.9830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 417ms/step - accuracy: 0.5479 - loss: 0.9821 - val_accuracy: 0.4638 - val_loss: 0.9797\n",
      "Epoch 4/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.6141 - loss: 0.8576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 413ms/step - accuracy: 0.6164 - loss: 0.8547 - val_accuracy: 0.5314 - val_loss: 0.9314\n",
      "Epoch 5/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 416ms/step - accuracy: 0.7801 - loss: 0.5912 - val_accuracy: 0.5507 - val_loss: 0.9656\n",
      "Epoch 6/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 414ms/step - accuracy: 0.8476 - loss: 0.3859 - val_accuracy: 0.5459 - val_loss: 1.1243\n",
      "Epoch 7/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 447ms/step - accuracy: 0.8973 - loss: 0.2776 - val_accuracy: 0.5845 - val_loss: 1.1646\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
      "\n",
      "🏁 Final Evaluation on Dutch Validation Set\n",
      "Accuracy: 0.5314009661835749\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.53      0.48      0.50        84\n",
      "     Neutral       0.48      0.58      0.53        71\n",
      "    Positive       0.62      0.56      0.59        52\n",
      "\n",
      "    accuracy                           0.53       207\n",
      "   macro avg       0.54      0.54      0.54       207\n",
      "weighted avg       0.54      0.53      0.53       207\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[40 33 11]\n",
      " [23 41  7]\n",
      " [12 11 29]]\n"
     ]
    }
   ],
   "source": [
    "# 🇳🇱 Dutch LSTM on Mac mini M4 Pro\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 1) File paths — update these to wherever you saved them\n",
    "dutch_csv      = \"/Users/feysal/Downloads/Dutch_sample_manually_labelled - dutch_comments_with_mapped_sentiment.csv\"\n",
    "fasttext_vec   = \"/Users/feysal/Downloads/cc.nl.300.vec\"\n",
    "\n",
    "# 2) Load & filter your manually labeled Dutch comments\n",
    "df = pd.read_csv(dutch_csv)\n",
    "df = df.dropna(subset=[\"Cleaned Comment Text\"])\n",
    "df = df[df[\"real_sentiment\"].isin([-1, 0, 1])]\n",
    "\n",
    "texts = df[\"Cleaned Comment Text\"].astype(str).tolist()\n",
    "labels = df[\"real_sentiment\"].map({-1:0, 0:1, 1:2}).to_numpy()  # map to 0/1/2 for sparse_categorical\n",
    "\n",
    "# 3) Tokenize & pad\n",
    "max_words = 10000\n",
    "max_len   = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# 4) Stratified train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, labels,\n",
    "    test_size=0.20,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5) Compute class weights\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# 6) Load FastText Dutch embeddings\n",
    "emb_dim = 300\n",
    "emb_index = {}\n",
    "with open(fasttext_vec, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    # If the first line is a header (vocab + dim), skip it:\n",
    "    first = f.readline().split()\n",
    "    if len(first) != emb_dim+1:\n",
    "        f.seek(0)  # not a header, rewind\n",
    "    for line in tqdm(f, desc=\"Loading FastText\"):\n",
    "        parts = line.rstrip().split(\" \")\n",
    "        word = parts[0]\n",
    "        vec  = np.asarray(parts[1:], dtype=\"float32\")\n",
    "        emb_index[word] = vec\n",
    "\n",
    "# 7) Build embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((max_words, emb_dim), dtype=\"float32\")\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "    if idx < max_words:\n",
    "        vec = emb_index.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "\n",
    "# 8) Construct the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim = max_words,\n",
    "              output_dim = emb_dim,\n",
    "              weights    = [embedding_matrix],\n",
    "              input_length = max_len,\n",
    "              trainable = True),\n",
    "    Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss      = \"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"adam\",\n",
    "    metrics   = [\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 9) Callbacks\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "mc = ModelCheckpoint(\"best_dutch_lstm.h5\", monitor=\"val_loss\", save_best_only=True)\n",
    "\n",
    "# 10) Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_val, y_val),\n",
    "    epochs          = 15,\n",
    "    batch_size      = 64,\n",
    "    class_weight    = class_weights,\n",
    "    callbacks       = [es, mc]\n",
    ")\n",
    "\n",
    "# 11) Evaluate\n",
    "model.load_weights(\"best_dutch_lstm.h5\")\n",
    "y_pred = model.predict(X_val).argmax(axis=1)\n",
    "\n",
    "print(\"\\n🏁 Final Evaluation on Dutch Validation Set\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_val, y_pred, target_names=[\"Negative\",\"Neutral\",\"Positive\"]))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc295102-5dfa-4ef8-b4b4-7460e0c1a4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
